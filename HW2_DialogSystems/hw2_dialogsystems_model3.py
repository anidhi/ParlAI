# -*- coding: utf-8 -*-
"""HW2_DialogSystems_Model3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cGqqm2pvMweo3ULWznmdyrf-WgIOcbsL
"""

from google.colab import drive
drive.mount('/content/gdrive')

# Commented out IPython magic to ensure Python compatibility.
# %ls /content/gdrive/'My Drive'

!pip install torch
import torch
model_save_name = 'HW2_model3'
path = F"/content/gdrive/My Drive/{model_save_name}"

!git clone https://github.com/facebookresearch/ParlAI
!cd ParlAI; python setup.py develop install

!pip install 'git+https://github.com/rsennrich/subword-nmt.git#egg=subword-nmt'

cd ParlAI/examples/

# Commented out IPython magic to ensure Python compatibility.
# %ls

mkdir models

cp /content/gdrive/'My Drive'/HW2_model3 models/HW2_model3

cp /content/gdrive/'My Drive'/HW2_model3.dict models/HW2_model3.dict

cp /content/gdrive/'My Drive'/HW2_model3.trainstats models/HW2_model3.trainstats

!python train_model.py -t twitter -m seq2seq -mf models/HW2_model3 --dict-file models/HW2_model3.dict -emb glove --beam-size 40 --inference beam -opt adam -esz 300 -nl 4 -dr 0.3 -bi True -att local --attention-time pre --rnn-class lstm --decoder same -bs 16 -lr 0.001 --max-train-time 10800 --save-every-n-secs  300 -mcs all

torch.save('models/HW2_model2.checkpoint', path)

!python3 eval_model.py -m seq2seq -t twitter -mf models/HW2_model3

!python3 interactive.py -m seq2seq -mf models/HW2_model3

cp models/HW2_model3 /content/gdrive/'My Drive'/HW2_model3

cp models/HW2_model3.dict /content/gdrive/'My Drive'/HW2_model3.dict

cp models/HW2_model3.trainstats /content/gdrive/'My Drive'/HW2_model3.trainstats

# Commented out IPython magic to ensure Python compatibility.
# %ls